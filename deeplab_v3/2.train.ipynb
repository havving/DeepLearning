{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random, os, time\n",
    "import tensorflow.contrib.slim as slim  # 기존 tensorflow를 사용하기 쉽게 만들어 놓은 high-level API\n",
    "\n",
    "from custom_op import conv2d, atrous_conv2d, relu, bn, max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- 설정 변수 정의 ---\n",
    "## 작업 디렉토리 정의\n",
    "# 학습 데이터 파일명\n",
    "train_list_file = \"/src/hyebin/deeplab_v3/train_data_256.npy\"\n",
    "# 라벨 데이터 파일명\n",
    "label_list_file = \"/src/hyebin/deeplab_v3/train_label_256.npy\"\n",
    "# 분석 모델 디렉토리명\n",
    "modeldir = \"/src/hyebin/model/A-DEEPLAB-V3-CRACK-01\"\n",
    "\n",
    "## 학습 데이터 설정\n",
    "# 학습할 데이터의 개수\n",
    "training_count = 17    # (18~ OOM Error)\n",
    "\n",
    "## 최적화 함수 설정\n",
    "# 최적화 함수 학습률\n",
    "learning_rate = 0.0001\n",
    "\n",
    "## 학습 수행 설정\n",
    "# 최대 학습 수행 횟수\n",
    "epoch_count = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train data:  /src/hyebin/deeplab_v3/train_data_256.npy\n",
      "load train label data:  /src/hyebin/deeplab_v3/train_label_256.npy\n",
      "(537, 256, 256, 1)\n",
      "(537, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "## --- 학습 데이터 로딩 ---\n",
    "# 데이터 구조\n",
    "# train_list : 학습용 데이터(이미지 개수, 256, 256, 1)\n",
    "# label_list : 학습용 라벨 데이터(이미지 개수, 256, 256, 1)\n",
    "print(\"load train data: \", train_list_file) \n",
    "train_list = np.load(train_list_file, allow_pickle=True)\n",
    "\n",
    "print(\"load train label data: \", label_list_file)\n",
    "label_list = np.load(label_list_file, allow_pickle=True)\n",
    "\n",
    "print(train_list.shape)\n",
    "print(label_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- ResNet 모델 구성 ---\n",
    "\n",
    "## 모든 convoltion 연산에 3x3 이하 크기의 커널 사용 \n",
    "## feature map의 크기가 같은 layer는 출력 feature map 갯수가 동일함\n",
    "## ResNet50 부터는 연산량을 줄이기 위해 Residual Block 내에 1x1, 3x3, 1x1 Convolution 연산을 쌓음\n",
    "## 1x1 Convolution 연산으로 feature map의 갯수를 줄였다가, 3x3 연산을 거친 후,\n",
    "## 1x1 Convolution 연산으로 차원을 늘려줌  (=병목 레이어)\n",
    "    \n",
    "## 차원이 같은 Residual(잔차) Block\n",
    "## 입력값과 출력값의 차원이 같을 경우, 단순 add 연산만 진행함\n",
    "def identity_block(inputs, filters, stage):\n",
    "    filter1, filter2, filter3 = filters\n",
    "    layer1 = relu(bn(conv2d(inputs, filter1, [1,1], name=stage+'_a_identity', padding='VALID')))\n",
    "    layer2 = relu(bn(conv2d(layer1, filter2, [3,3], name=stage+'_b_identity')))\n",
    "    layer3 = bn(conv2d(layer2, filter3, [1,1], name=stage+'_c_identity', padding='VALID'))\n",
    "    layer4 = relu(tf.add(layer3, inputs))\n",
    "    return layer4\n",
    "    \n",
    "    \n",
    "## 차원이 다른 Residual(잔차) Block\n",
    "## 입력값과 출력값의 차원이 다름\n",
    "## 차원이 다르기 때문에 Conv_layer를 통해 projection shortcut\n",
    "## projection shortcut : 입력값을 바로 더하지 않고 \n",
    "##           1x1 convolution 연산을 stride를 설정하여 freature map의 크기와 개수를 맞춰준 후 더해줌\n",
    "##           (즉, projection을 통해 차원을 맞춰주는 작업)\n",
    "def conv_block(inputs, depths, stage, s=2):\n",
    "    depth1, depth2, depth3 = depths\n",
    "    layer1 = relu(bn(conv2d(inputs, depth1, [1,1], name=stage+'_a_conv', strides=[1, s, s, 1], padding='VALID')))\n",
    "    layer2 = relu(bn(conv2d(layer1, depth2, [3,3], name=stage+'_b_conv')))\n",
    "    layer3 = bn(conv2d(layer2, depth3, [1,1], name=stage+'_c_conv', padding='VALID'))\n",
    "    shortcut = bn(conv2d(inputs, depth3, [1,1], name=stage+'_shortcut', strides=[1, s, s, 1], padding='VALID'))\n",
    "    layer4 = relu(tf.add(layer3, shortcut))\n",
    "    return layer4\n",
    "    \n",
    "\n",
    "## 입력값과 출력값의 차원이 같은 Atrous Convolution 구조의 Residual(잔차) Block\n",
    "def atrous_identity_block(inputs, depths, stage, rate):\n",
    "    depth1, depth2, depth3 = depths\n",
    "    layer1 = relu(bn(atrous_conv2d(inputs, depth1, [1,1], rate, name=stage+'_a_identity')))\n",
    "    layer2 = relu(bn(atrous_conv2d(layer1, depth2, [3,3], rate, name=stage+'_b_identity')))\n",
    "    layer3 = bn(atrous_conv2d(layer2, depth3, [1,1], rate, name=stage+'_c_identity'))\n",
    "    layer4 = relu(tf.add(layer3, inputs))\n",
    "    return layer4\n",
    "    \n",
    "    \n",
    "## 입력값과 출력값의 차원이 다른 Atrous Convolution 구조의 Residual(잔차) Block    \n",
    "def atrous_conv_block(inputs, depths, stage, rate, s=2):\n",
    "    depth1, depth2, depth3 = depths\n",
    "    layer1 = relu(bn(atrous_conv2d(inputs, depth1, [1,1], rate, name=stage+'_a_conv')))\n",
    "    layer2 = relu(bn(atrous_conv2d(layer1, depth2, [3,3], rate, name=stage+'_b_conv')))\n",
    "    layer3 = bn(atrous_conv2d(layer2, depth3, [1,1], rate, name=stage+'_c_conv'))\n",
    "    shortcut = bn(conv2d(inputs, depth3, [1,1], name=stage+'_shortcut', strides=[1, s, s, 1], padding='VALID'))\n",
    "    layer4 = relu(tf.add(layer3, shortcut))\n",
    "    return layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /src/hyebin/deeplab_v3/custom_op.py:10: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /src/hyebin/deeplab_v3/custom_op.py:40: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "conv : Tensor(\"ResNet50/encoder/pool1:0\", shape=(?, 64, 64, 64), dtype=float32)\n",
      "conv1 : Tensor(\"ResNet50/encoder/Relu_9:0\", shape=(?, 64, 64, 256), dtype=float32)\n",
      "conv2 : Tensor(\"ResNet50/encoder/Relu_18:0\", shape=(?, 32, 32, 512), dtype=float32)\n",
      "conv3 : Tensor(\"ResNet50/encoder/Relu_36:0\", shape=(?, 32, 32, 1024), dtype=float32)\n",
      "conv4 : Tensor(\"ResNet50/encoder/Relu_45:0\", shape=(?, 32, 32, 2048), dtype=float32)\n",
      "\n",
      "feature_map : Tensor(\"ResNet50/ASPP/ResizeBilinear:0\", shape=(?, 32, 32, 256), dtype=float32)\n",
      "rate1 : Tensor(\"ResNet50/ASPP/rate1/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32)\n",
      "rate6 : Tensor(\"ResNet50/ASPP/rate6/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32)\n",
      "rate12 : Tensor(\"ResNet50/ASPP/rate12/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32)\n",
      "rate18 : Tensor(\"ResNet50/ASPP/rate18/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32)\n",
      "concated : Tensor(\"ResNet50/ASPP/concat:0\", shape=(?, 32, 32, 1280), dtype=float32)\n",
      "net : Tensor(\"ResNet50/ASPP/net/BiasAdd:0\", shape=(?, 32, 32, 256), dtype=float32)\n",
      "\n",
      "logits : Tensor(\"ResizeBilinear:0\", shape=(?, 256, 256, 2), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: calling expand_dims (from tensorflow.python.ops.array_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "\n",
      "pred : Tensor(\"pred:0\", shape=(?, 256, 256, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "## --- 신경망 구성 ---\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# --- 입력층 ---\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 256, 256, 1], name=\"in\")\n",
    "y = tf.placeholder(dtype=tf.int64, shape=[None, 256, 256, 1], name=\"out\")\n",
    "\n",
    "## ResNet을 사용하여 특징 추출 (Encoder)\n",
    "    \n",
    "# ResNet50 : Convolution 연산 + Fully Connected Layer만 계산했을 때, 총 50개의 Layer (CNN)\n",
    "# layer가 깊어질수록 성능이 더 좋아진다고 생각 (VGG-19보다 더 깊게 설계)\n",
    "with tf.variable_scope('ResNet50') as scope:\n",
    "    with tf.variable_scope('encoder') as scope:\n",
    "        # strides : 필터를 적용하는 간격 (필터의 이동량)\n",
    "        conv = conv2d(x, 64, [7,7], strides=[1,2,2,1], name='conv1')   # size 1/2\n",
    "        # bn : tf.contrib.layers.batch_norm (Batch Normalization)\n",
    "        # Batch Normalization : 신경망을 안정시켜주는 표준화 기법 \n",
    "        conv = bn(conv)\n",
    "        # relu : tf.nn.relu\n",
    "        conv = relu(conv)\n",
    "        # max_pool : Pooling Layer (tf.nn.max_pool)\n",
    "        conv = max_pool(conv, ksize=[1,3,3,1], name='pool1')   # size 1/4\n",
    "        print('conv : {}'.format(conv))\n",
    "    \n",
    "        conv = conv_block(conv, [64, 64, 256], '2_1', s=1)\n",
    "        conv = identity_block(conv, [64, 64, 256], '2_2')\n",
    "        conv = identity_block(conv, [64, 64, 256], '2_3')\n",
    "        print('conv1 : {}'.format(conv))\n",
    "    \n",
    "        conv = conv_block(conv, [128, 128, 512], '3_1')\n",
    "        conv = identity_block(conv, [128, 128, 512], '3_2')\n",
    "        conv = identity_block(conv, [128, 128, 512], '3_3')\n",
    "        print('conv2 : {}'.format(conv))\n",
    "    \n",
    "        conv = atrous_conv_block(conv, [256, 256, 1024], '4_1', 2, s=1)\n",
    "        conv = atrous_identity_block(conv, [256, 256, 1024], '4_2',  2)\n",
    "        conv = atrous_identity_block(conv, [256, 256, 1024], '4_3',  2)\n",
    "        conv = atrous_identity_block(conv, [256, 256, 1024], '4_4',  2)\n",
    "        conv = atrous_identity_block(conv, [256, 256, 1024], '4_5',  2)\n",
    "        conv = atrous_identity_block(conv, [256, 256, 1024], '4_6',  2)\n",
    "        print('conv3 : {}'.format(conv))\n",
    "        \n",
    "        conv = atrous_conv_block(conv, [512, 512, 2048], '5_1', 4, s=1)\n",
    "        conv = atrous_identity_block(conv, [512, 512, 2048], '5_2', 4)\n",
    "        conv = atrous_identity_block(conv, [512, 512, 2048], '5_3', 4)\n",
    "        print('conv4 : {}'.format(conv))\n",
    "    \n",
    "\n",
    "    ## Atrous Pyrimid Pooling (Decoder)\n",
    "        \n",
    "    # ASPP : Atrous + Spatial Pyramid Pooling\n",
    "    #      : rate를 다양하게 변환시켜 다양한 RF(Receptive Field)가 고려된 feature map을 생성할 수 있도록 함\n",
    "    #      : 연산의 효율성 증가, 고정된 RF보다 다양하게 변화시킨 RF가 성능 향상 효과\n",
    "    with tf.variable_scope('ASPP') as scope:\n",
    "        feature_map_shape = conv.get_shape().as_list()\n",
    "    \n",
    "        # global average pooling\n",
    "        # feature맵의 width, height 평균을 냄\n",
    "        feature_map = tf.reduce_mean(conv, [1,2], keepdims=True)  # keepdims:차원 유지 여부\n",
    "    \n",
    "        feature_map = conv2d(feature_map, 256, [1,1], name='gap_feature_map')\n",
    "        feature_map = tf.image.resize_bilinear(feature_map, [feature_map_shape[1], feature_map_shape[2]])\n",
    "        print('\\nfeature_map : {}'.format(feature_map))\n",
    "     \n",
    "        # rate : 필터의 픽셀 간의 거리를 나타내는 확장 비율\n",
    "        rate1 = conv2d(conv, 256, [1,1], name='rate1')\n",
    "        print('rate1 : {}'.format(rate1))\n",
    "        rate6 = atrous_conv2d(conv, 256, [3,3], rate=6, name='rate6')\n",
    "        print('rate6 : {}'.format(rate6))\n",
    "        rate12 = atrous_conv2d(conv, 256, [3,3], rate=12, name='rate12')\n",
    "        print('rate12 : {}'.format(rate12))\n",
    "        rate18 = atrous_conv2d(conv, 256, [3,3], rate=18, name='rate18')\n",
    "        print('rate18 : {}'.format(rate18))\n",
    "        concated = tf.concat([feature_map, rate1, rate6, rate12, rate18], axis=3)  # concat:tensor 객체를 횡(가로) 방향으로 연결 (axis=3차원)\n",
    "        print('concated : {}'.format(concated))\n",
    "\n",
    "        net = conv2d(concated, 256, [1,1], name='net')\n",
    "        print('net : {}'.format(net))\n",
    "    \n",
    "# logits:Neural Network의 최종 레이어가 내놓은 결과값\n",
    "logits = conv2d(net, 2, [1,1], name='logits')\n",
    "logits = tf.image.resize_bilinear(logits, size=[256, 256])\n",
    "print('\\nlogits : {}'.format(logits))\n",
    "    \n",
    "# 예측값\n",
    "pred = tf.argmax(logits, axis=3)  # argmax:1차원 배열에서 가장 큰 값을 찾아 index return\n",
    "pred = tf.expand_dims(pred, dim=3, name='pred')  # expand_dims:axis로 지정된 차원을 추가\n",
    "print('\\npred : {}'.format(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ResizeBilinear:0\", shape=(?, 256, 256, 2), dtype=float32)\n",
      "Tensor(\"out:0\", shape=(?, 256, 256, 1), dtype=int64)\n",
      "loss : Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "loss_summ : Tensor(\"Merge/MergeSummary:0\", shape=(), dtype=string)\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "ResNet50/encoder/conv1/conv_weight:0 (float32_ref 7x7x1x64) [3136, bytes: 12544]\n",
      "ResNet50/encoder/conv1/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_1_a_conv/conv_weight:0 (float32_ref 1x1x64x64) [4096, bytes: 16384]\n",
      "ResNet50/encoder/2_1_a_conv/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_1_b_conv/conv_weight:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "ResNet50/encoder/2_1_b_conv/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_1_c_conv/conv_weight:0 (float32_ref 1x1x64x256) [16384, bytes: 65536]\n",
      "ResNet50/encoder/2_1_c_conv/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_3/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_3/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/2_1_shortcut/conv_weight:0 (float32_ref 1x1x64x256) [16384, bytes: 65536]\n",
      "ResNet50/encoder/2_1_shortcut/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_4/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_4/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/2_2_a_identity/conv_weight:0 (float32_ref 1x1x256x64) [16384, bytes: 65536]\n",
      "ResNet50/encoder/2_2_a_identity/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_5/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_5/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_2_b_identity/conv_weight:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "ResNet50/encoder/2_2_b_identity/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_6/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_6/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_2_c_identity/conv_weight:0 (float32_ref 1x1x64x256) [16384, bytes: 65536]\n",
      "ResNet50/encoder/2_2_c_identity/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_7/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_7/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/2_3_a_identity/conv_weight:0 (float32_ref 1x1x256x64) [16384, bytes: 65536]\n",
      "ResNet50/encoder/2_3_a_identity/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_8/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_8/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_3_b_identity/conv_weight:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "ResNet50/encoder/2_3_b_identity/conv_bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_9/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/BatchNorm_9/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "ResNet50/encoder/2_3_c_identity/conv_weight:0 (float32_ref 1x1x64x256) [16384, bytes: 65536]\n",
      "ResNet50/encoder/2_3_c_identity/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_10/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_10/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/3_1_a_conv/conv_weight:0 (float32_ref 1x1x256x128) [32768, bytes: 131072]\n",
      "ResNet50/encoder/3_1_a_conv/conv_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_11/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_11/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/3_1_b_conv/conv_weight:0 (float32_ref 3x3x128x128) [147456, bytes: 589824]\n",
      "ResNet50/encoder/3_1_b_conv/conv_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_12/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_12/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/3_1_c_conv/conv_weight:0 (float32_ref 1x1x128x512) [65536, bytes: 262144]\n",
      "ResNet50/encoder/3_1_c_conv/conv_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_13/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_13/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/3_1_shortcut/conv_weight:0 (float32_ref 1x1x256x512) [131072, bytes: 524288]\n",
      "ResNet50/encoder/3_1_shortcut/conv_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_14/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_14/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/3_2_a_identity/conv_weight:0 (float32_ref 1x1x512x128) [65536, bytes: 262144]\n",
      "ResNet50/encoder/3_2_a_identity/conv_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_15/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_15/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/3_2_b_identity/conv_weight:0 (float32_ref 3x3x128x128) [147456, bytes: 589824]\n",
      "ResNet50/encoder/3_2_b_identity/conv_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_16/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_16/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/3_2_c_identity/conv_weight:0 (float32_ref 1x1x128x512) [65536, bytes: 262144]\n",
      "ResNet50/encoder/3_2_c_identity/conv_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_17/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_17/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/3_3_a_identity/conv_weight:0 (float32_ref 1x1x512x128) [65536, bytes: 262144]\n",
      "ResNet50/encoder/3_3_a_identity/conv_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_18/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_18/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/3_3_b_identity/conv_weight:0 (float32_ref 3x3x128x128) [147456, bytes: 589824]\n",
      "ResNet50/encoder/3_3_b_identity/conv_bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_19/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/BatchNorm_19/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "ResNet50/encoder/3_3_c_identity/conv_weight:0 (float32_ref 1x1x128x512) [65536, bytes: 262144]\n",
      "ResNet50/encoder/3_3_c_identity/conv_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_20/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_20/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/4_1_a_conv/atrous_weight:0 (float32_ref 1x1x512x256) [131072, bytes: 524288]\n",
      "ResNet50/encoder/4_1_a_conv/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_21/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_21/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_1_b_conv/atrous_weight:0 (float32_ref 3x3x256x256) [589824, bytes: 2359296]\n",
      "ResNet50/encoder/4_1_b_conv/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_22/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_22/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_1_c_conv/atrous_weight:0 (float32_ref 1x1x256x1024) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_1_c_conv/atrous_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_23/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_23/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/4_1_shortcut/conv_weight:0 (float32_ref 1x1x512x1024) [524288, bytes: 2097152]\n",
      "ResNet50/encoder/4_1_shortcut/conv_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_24/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_24/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/4_2_a_identity/atrous_weight:0 (float32_ref 1x1x1024x256) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_2_a_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_25/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_25/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_2_b_identity/atrous_weight:0 (float32_ref 3x3x256x256) [589824, bytes: 2359296]\n",
      "ResNet50/encoder/4_2_b_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_26/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_26/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_2_c_identity/atrous_weight:0 (float32_ref 1x1x256x1024) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_2_c_identity/atrous_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_27/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_27/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/4_3_a_identity/atrous_weight:0 (float32_ref 1x1x1024x256) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_3_a_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_28/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_28/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_3_b_identity/atrous_weight:0 (float32_ref 3x3x256x256) [589824, bytes: 2359296]\n",
      "ResNet50/encoder/4_3_b_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_29/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_29/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_3_c_identity/atrous_weight:0 (float32_ref 1x1x256x1024) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_3_c_identity/atrous_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_30/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_30/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/4_4_a_identity/atrous_weight:0 (float32_ref 1x1x1024x256) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_4_a_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_31/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_31/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_4_b_identity/atrous_weight:0 (float32_ref 3x3x256x256) [589824, bytes: 2359296]\n",
      "ResNet50/encoder/4_4_b_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_32/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_32/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_4_c_identity/atrous_weight:0 (float32_ref 1x1x256x1024) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_4_c_identity/atrous_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_33/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_33/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/4_5_a_identity/atrous_weight:0 (float32_ref 1x1x1024x256) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_5_a_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_34/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_34/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_5_b_identity/atrous_weight:0 (float32_ref 3x3x256x256) [589824, bytes: 2359296]\n",
      "ResNet50/encoder/4_5_b_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_35/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_35/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_5_c_identity/atrous_weight:0 (float32_ref 1x1x256x1024) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_5_c_identity/atrous_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_36/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_36/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/4_6_a_identity/atrous_weight:0 (float32_ref 1x1x1024x256) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_6_a_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_37/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_37/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_6_b_identity/atrous_weight:0 (float32_ref 3x3x256x256) [589824, bytes: 2359296]\n",
      "ResNet50/encoder/4_6_b_identity/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_38/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/BatchNorm_38/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/encoder/4_6_c_identity/atrous_weight:0 (float32_ref 1x1x256x1024) [262144, bytes: 1048576]\n",
      "ResNet50/encoder/4_6_c_identity/atrous_bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_39/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/BatchNorm_39/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "ResNet50/encoder/5_1_a_conv/atrous_weight:0 (float32_ref 1x1x1024x512) [524288, bytes: 2097152]\n",
      "ResNet50/encoder/5_1_a_conv/atrous_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_40/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_40/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/5_1_b_conv/atrous_weight:0 (float32_ref 3x3x512x512) [2359296, bytes: 9437184]\n",
      "ResNet50/encoder/5_1_b_conv/atrous_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_41/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_41/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/5_1_c_conv/atrous_weight:0 (float32_ref 1x1x512x2048) [1048576, bytes: 4194304]\n",
      "ResNet50/encoder/5_1_c_conv/atrous_bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_42/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_42/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/5_1_shortcut/conv_weight:0 (float32_ref 1x1x1024x2048) [2097152, bytes: 8388608]\n",
      "ResNet50/encoder/5_1_shortcut/conv_bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_43/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_43/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/5_2_a_identity/atrous_weight:0 (float32_ref 1x1x2048x512) [1048576, bytes: 4194304]\n",
      "ResNet50/encoder/5_2_a_identity/atrous_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_44/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_44/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/5_2_b_identity/atrous_weight:0 (float32_ref 3x3x512x512) [2359296, bytes: 9437184]\n",
      "ResNet50/encoder/5_2_b_identity/atrous_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_45/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_45/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/5_2_c_identity/atrous_weight:0 (float32_ref 1x1x512x2048) [1048576, bytes: 4194304]\n",
      "ResNet50/encoder/5_2_c_identity/atrous_bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_46/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_46/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/5_3_a_identity/atrous_weight:0 (float32_ref 1x1x2048x512) [1048576, bytes: 4194304]\n",
      "ResNet50/encoder/5_3_a_identity/atrous_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_47/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_47/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/5_3_b_identity/atrous_weight:0 (float32_ref 3x3x512x512) [2359296, bytes: 9437184]\n",
      "ResNet50/encoder/5_3_b_identity/atrous_bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_48/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/BatchNorm_48/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "ResNet50/encoder/5_3_c_identity/atrous_weight:0 (float32_ref 1x1x512x2048) [1048576, bytes: 4194304]\n",
      "ResNet50/encoder/5_3_c_identity/atrous_bias:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_49/beta:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/encoder/BatchNorm_49/gamma:0 (float32_ref 2048) [2048, bytes: 8192]\n",
      "ResNet50/ASPP/gap_feature_map/conv_weight:0 (float32_ref 1x1x2048x256) [524288, bytes: 2097152]\n",
      "ResNet50/ASPP/gap_feature_map/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/ASPP/rate1/conv_weight:0 (float32_ref 1x1x2048x256) [524288, bytes: 2097152]\n",
      "ResNet50/ASPP/rate1/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/ASPP/rate6/atrous_weight:0 (float32_ref 3x3x2048x256) [4718592, bytes: 18874368]\n",
      "ResNet50/ASPP/rate6/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/ASPP/rate12/atrous_weight:0 (float32_ref 3x3x2048x256) [4718592, bytes: 18874368]\n",
      "ResNet50/ASPP/rate12/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/ASPP/rate18/atrous_weight:0 (float32_ref 3x3x2048x256) [4718592, bytes: 18874368]\n",
      "ResNet50/ASPP/rate18/atrous_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "ResNet50/ASPP/net/conv_weight:0 (float32_ref 1x1x1280x256) [327680, bytes: 1310720]\n",
      "ResNet50/ASPP/net/conv_bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "logits/conv_weight:0 (float32_ref 1x1x256x2) [512, bytes: 2048]\n",
      "logits/conv_bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 38781570\n",
      "Total bytes of variables: 155126280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38781570, 155126280)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## --- loss 함수 정의 ---\n",
    "# sparse_softmax_cross_entropy_with_logits:실측값인 label의 값은 인덱스의 숫자를 그대로 사용하고, \n",
    "#                                          예측 모델의 출력값은 인덱스의 one-hot encoding을 사용\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.squeeze(y, [3])))\n",
    "print(logits)\n",
    "print(y)\n",
    "loss_summ = tf.summary.merge([tf.summary.scalar('loss', loss)])\n",
    "\n",
    "print('loss : {}'.format(loss))\n",
    "print('loss_summ : {}'.format(loss_summ))\n",
    "\n",
    "## --- loss 함수의 최적화 함수 정의 ---\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "model_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(model_vars, print_info=True)  # 현재 올라와있는 모든 트레이닝 변수명을 순서에 맞춰 출력해줌(scope)\n",
    "                                                                # 변수 개수, 용량 등을 쉽게 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_batch : 31\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2f19e8bd6313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtraining_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtraining_count\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtraining_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss_summ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_summ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loss_summ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## --- 학습 수행 및  모델 저장 ---\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(modeldir + \"/logs\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # 신경망 가중치(weight) 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    total_batch = int(train_list.shape[0] / training_count)\n",
    "    print('total_batch : {}\\n'.format(total_batch))\n",
    "    counter = 0\n",
    "    \n",
    "    # 전체 데이터에 대해 100번 학습 수행\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch_count):\n",
    "        total_loss = 0\n",
    "        random.shuffle(train_list)  # 매 epoch마다 데이터셋 shuffling\n",
    "        random.shuffle(label_list)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            # 학습용 데이터와 라벨\n",
    "            # 랜덤 데이터를 training_count 만큼 가져옴\n",
    "            train_x = train_list[i*training_count:i*training_count+training_count]\n",
    "            train_y = label_list[i*training_count:i*training_count+training_count]\n",
    "            \n",
    "            _, _loss_summ, _loss = sess.run([optimizer, loss_summ, loss], feed_dict={x:train_x, y:train_y})\n",
    "            writer.add_summary(summary = _loss_summ, global_step = counter)\n",
    "            counter += 1\n",
    "            total_loss += _loss\n",
    "            \n",
    "        print('Epoch:', '%03d' % (epoch + 1), ' Avg Loss: {:.6}\\t'.format(_loss))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"running time: \", end_time - start_time)\n",
    "    \n",
    "    ## --- 학습 모델 저장 ---\n",
    "    print(\"\\nsave model\\n\")\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(modeldir + \"/model_12\")\n",
    "    signature = tf.saved_model.predict_signature_def(inputs={\"in\":x}, outputs={\"out\":pred})\n",
    "    builder.add_meta_graph_and_variables(sess, tags=[\"ver1\"], signature_def_map={\"deep-crack-train-v1\":signature})\n",
    "    builder.save()\n",
    "    print(\"\\ncomplete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
