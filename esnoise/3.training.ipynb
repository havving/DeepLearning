{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- config : utf-8 -*-\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 설정 변수 정의 ---\n",
    "# 작업 디렉토리 정의\n",
    "# 학습 데이터 파일명\n",
    "noise_list_file = \"/src/hyebin/esnoise/noise_spec_data.npy\"\n",
    "# 라벨 데이터 파일명\n",
    "noise_label_list_file = \"/src/hyebin/esnoise/noise_label_data.npy\"\n",
    "# 진동 분석 모델 디렉토리명\n",
    "modeldir = \"/src/hyebin/model/NOISE-SPEC-01\"\n",
    "# tensorboard 용 log 디렉토리명\n",
    "tblogdir = \"/src/hyebin/logs\"\n",
    "\n",
    "# 학습 데이터 설정\n",
    "# 학습할 데이터의 개수\n",
    "training_count = 2000\n",
    "\n",
    "# 전결합층 설정\n",
    "# 전결합층 첫번째 레이어 unit 개수\n",
    "layer1_unit_count = 1024\n",
    "# 전결합층 두번째 레이어 unit 개수\n",
    "layer2_unit_count = 1024\n",
    "# 전결합층 세번째 레이어 unit 개수\n",
    "layer3_unit_count = 1024\n",
    "# 전결합층 dropout 비율\n",
    "dropout_rate = 0.4\n",
    "\n",
    "# 최적화 함수 설정\n",
    "# 최적화 함수 학습률\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# 학습 수행 설정\n",
    "# 최대 학습 수행 횟수\n",
    "epoch_count = 5000\n",
    "# 학습 중단 시킬, 최소 loss값\n",
    "loss_limit = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load noise data: /src/hyebin/esnoise/noise_spec_data.npy\n",
      "load complete\n",
      "load noise label data: /src/hyebin/esnoise/noise_label_data.npy\n",
      "load complete\n",
      "(18000, 48, 64, 3)\n",
      "(18000, 18)\n"
     ]
    }
   ],
   "source": [
    "# --- 학습 데이터 로딩 ---\n",
    "# 데이터 구조\n",
    "# noise_list : 학습용 데이터(이미지 개수, 48, 64, 3)\n",
    "# noise_label_list : 학습용 라벨 데이터(이미지 개수, 18)\n",
    "print(\"load noise data:\", noise_list_file)\n",
    "noise_list = np.load(noise_list_file, allow_pickle=True)\n",
    "print(\"load complete\")\n",
    "\n",
    "print(\"load noise label data:\", noise_label_list_file)\n",
    "org_noise_label_list = np.load(noise_label_list_file, allow_pickle=True)\n",
    "\n",
    "# one hot encoding\n",
    "noise_label_list = []\n",
    "unit_matrix = np.identity(18)\n",
    "for index in org_noise_label_list:\n",
    "    one_hot = unit_matrix[index:index+1][0]\n",
    "    noise_label_list.append(one_hot)\n",
    "\n",
    "noise_label_list = np.array(noise_label_list)\n",
    "\n",
    "print(\"load complete\")\n",
    "\n",
    "print(noise_list.shape)\n",
    "print(noise_label_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-cfa54e9193fc>:22: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-cfa54e9193fc>:36: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-cfa54e9193fc>:86: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-cfa54e9193fc>:87: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss : Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.Operation'>\n",
      "train : name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_conv2d/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_1/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_2/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_2/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_3/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_3/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_4/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_4/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_5/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2d_5/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_1/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_2/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_2/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_3/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense_3/bias/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- VGG Net 신경망 구성 ---\n",
    "#     입력층 : 48*64 의 Spectrogram 전처리 데이터\n",
    "#     특징 추출층 : 2개 합성곱 필터, 1개의 필터를 2회 수행 \n",
    "#     전 결합층 : 3개의 은닉층(층당 유닛 1024개) → 단층에서 발생하는 xor 문제 회피, \n",
    "#                1개의 출력층(유닛 5개)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# dropout 사용 여부\n",
    "dropout_rate = tf.placeholder_with_default(0, shape=[], name=\"dropout_rate\")\n",
    "\n",
    "# --- 입력층 ---\n",
    "# Spectrogram\n",
    "x = tf.placeholder(tf.float32, [None, 48, 64, 3], name=\"in\")\n",
    "\n",
    "# --- 특징 추출층 ---\n",
    "conv11 = tf.layers.conv2d(\n",
    "    inputs=x,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "conv12 = tf.layers.conv2d(\n",
    "    inputs=conv11,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# 풀링으로 사이즈가 줄어듦\n",
    "# Spectrogram : 48 * 64 → 24 * 32\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    inputs=conv12,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2)\n",
    "\n",
    "conv21 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "conv22 = tf.layers.conv2d(\n",
    "    inputs=conv21,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# 풀링으로 사이즈가 줄어듦\n",
    "# Spectrogram : 24 * 32 → 12 * 16\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "    inputs=conv22,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2)\n",
    "\n",
    "conv31 = tf.layers.conv2d(\n",
    "    inputs=pool2,\n",
    "    filters=128,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "conv32 = tf.layers.conv2d(\n",
    "    inputs=conv31,\n",
    "    filters=128,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# 풀링으로 사이즈가 줄어듦\n",
    "# Spectrogram : 12 * 16 → 6 * 8\n",
    "pool3 = tf.layers.max_pooling2d(\n",
    "    inputs=conv32,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2)\n",
    "\n",
    "# --- 전 결합층 ---\n",
    "# 데이터 행렬 평탄화(flatten)\n",
    "# Spectrogram : 6 * 8(이미지사이즈) * 128(합성곱 필터 수)\n",
    "input_cnt = 6 * 8 * 128\n",
    "pool_flat = tf.reshape(pool3, [-1, input_cnt])\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=pool_flat, units=layer1_unit_count, activation=tf.nn.relu)\n",
    "dropout1 = tf.layers.dropout(inputs=dense1, rate=dropout_rate)\n",
    "\n",
    "dense2 = tf.layers.dense(inputs=dropout1, units=layer2_unit_count, activation=tf.nn.relu)\n",
    "dropout2 = tf.layers.dropout(inputs=dense2, rate=dropout_rate)\n",
    "\n",
    "dense3 = tf.layers.dense(inputs=dropout2, units=layer3_unit_count, activation=tf.nn.relu)\n",
    "dropout3 = tf.layers.dropout(inputs=dense3, rate=dropout_rate)\n",
    "\n",
    "netout = tf.layers.dense(inputs=dropout3, units=18)\n",
    "softout = tf.nn.softmax(netout, name=\"out\")\n",
    "\n",
    "# --- loss 함수 정의 ---\n",
    "# 평균 제곱 오차 함수 사용\n",
    "y = tf.placeholder(tf.float32, [None, 18])\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(softout - y), 1))\n",
    "\n",
    "print(type(loss))\n",
    "print('loss : {}'.format(loss))\n",
    "\n",
    "loss_summ = tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# --- loss 함수의 최적화 함수 정의 ---\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= 0   loss= 0.9444577\n",
      "index= 100   loss= 0.54797024\n",
      "index= 200   loss= 0.10793387\n",
      "index= 300   loss= 0.02527571\n",
      "index= 400   loss= 0.013466772\n",
      "index= 500   loss= 0.0048711714\n",
      "index= 600   loss= 0.0050850874\n",
      "index= 700   loss= 0.0022025933\n",
      "index= 800   loss= 0.0011179049\n",
      "index= 900   loss= 0.00029893633\n",
      "index= 1000   loss= 0.00037744085\n",
      "index= 1100   loss= 0.00015496383\n",
      "index= 1119   loss= 9.948237e-05\n",
      "running time: 532.6603753566742\n",
      "save model\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: /src/hyebin/model/NOISE-SPEC-01",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7ea760ae2502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# --- 학습 모델 저장 ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"save model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeldir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"in\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msoftout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_meta_graph_and_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ver1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_def_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"escalator-vibration-analysis-v1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, export_dir)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_collections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massets_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/builder_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, export_dir)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;34m\"Export directory already exists, and isn't empty. Please choose \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;34m\"a different export directory, or delete all the contents of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \"specified directory: %s\" % export_dir)\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: /src/hyebin/model/NOISE-SPEC-01"
     ]
    }
   ],
   "source": [
    "# --- 학습 수행 및 모델 저장---\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # tensorboard 용 로깅 정의    \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(tblogdir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # 신경망 가중치(weight) 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 전체 데이터에 대해 5000번 수행\n",
    "    # loss가 0.001 이하일때, 학습 중단\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch_count):\n",
    "        \n",
    "        # 학습용 데이터와 라벨\n",
    "        # 랜덤 데이터를 training_count 만큼 가져옴\n",
    "        base_index = np.random.randint(noise_label_list.shape[0] - training_count)\n",
    "        train_x = noise_list[base_index:base_index + training_count]\n",
    "        train_y = noise_label_list[base_index:base_index + training_count]\n",
    "\n",
    "        # 학습 수행\n",
    "        _train, _loss_summ, _loss = sess.run([train, loss_summ, loss], feed_dict={x:train_x, y:train_y, dropout_rate:0.4})\n",
    "        writer.add_summary(summary = _loss_summ, global_step = epoch)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"index=\", epoch, \"  loss=\", _loss)\n",
    "            \n",
    "        if _loss < loss_limit:\n",
    "            print(\"index=\", epoch, \"  loss=\", _loss)\n",
    "            break\n",
    "            \n",
    "    end_time = time.time()\n",
    "    print(\"running time:\", end_time - start_time)\n",
    "    \n",
    "    # --- 학습 모델 저장 ----\n",
    "    print(\"save model\")\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(modeldir)\n",
    "    signature = tf.saved_model.predict_signature_def(inputs={\"in\":x}, outputs={\"out\":softout})\n",
    "    builder.add_meta_graph_and_variables(sess, tags=[\"ver1\"], signature_def_map={\"escalator-vibration-analysis-v1\":signature})\n",
    "    builder.save()\n",
    "    print(\"complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
