{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 케라스 모델 구성\n",
    "import tensorflow as tf \n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend,activations\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# 모델 저장\n",
    "from keras.models import load_model\n",
    "\n",
    "# 멀티 GPU 사용\n",
    "# from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정 변수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업 Directory 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 파일명\n",
    "train_list_file = \"/src/data/crack/Cracks/resize/imgs_crack_train.npy\"\n",
    "# 라벨 데이터 파일명\n",
    "label_list_file = \"/src/data/crack/Cracks/resize/labels_crack_train.npy\"\n",
    "# 분석 모델 디렉토리명ㅣ\n",
    "model_dir = \"/src/hyebin/model/TEST/KERAS-TEST-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 데이터의 개수 (batch_size)\n",
    "training_count = 20  # 40\n",
    "\n",
    "## 최적화 함수 설정\n",
    "# 최적화 함수 학습률\n",
    "learning_rate = 0.00001\n",
    "\n",
    "## 학습 수행 설정\n",
    "# 최대 학습 수행 횟수\n",
    "epoch_count = 5  # 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성을 위한 연산 함수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 연산 생성 함수\n",
    "convolution 연산 수행<br>\n",
    "\n",
    "in_x : 입력 데이터<br>\n",
    "kernel_size(default=5)<br>\n",
    "strides(default=1)<br>\n",
    "activation(default='relu')<br>\n",
    "padding(default='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_x, filters, kernel_size=7, strides=1, activation='relu', padding='same'):\n",
    "    x = Conv2D(filters, \n",
    "               (kernel_size, kernel_size),\n",
    "               strides=strides,\n",
    "               activation='relu',\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same') (in_x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 폴링 연산 생성 함수\n",
    "maxpooling 연산 수행<br>\n",
    "\n",
    "in_x : 입력 데이터<br>\n",
    "kernel_size(default=(2,2))<br>\n",
    "strides(default=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling(in_x, kernel_size=(2, 2), strides=2):\n",
    "    x = MaxPooling2D(kernel_size, strides=strides) (in_x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## up-sampling, up-convolution 연산 생성 함수\n",
    "decoding 구간에서 사용하는 convolution 및 concatenate 수행<br>\n",
    "\n",
    "d_x : concat시 합칠 데이터<br>\n",
    "u_x : 확장할 데이터<br>\n",
    "filters : 필터 수<br>\n",
    "kernel_size(default=2)<br>\n",
    "strides(default=2)<br>\n",
    "activation(default='relu')<br>\n",
    "axis : concat 수행할 축 설정(default='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upConv(d_x, u_x, filters, kernel_size=7, strides=2, activation = 'relu', axis = None):\n",
    "    \n",
    "    x = Conv2DTranspose(filters, kernel_size, strides=strides, padding='same') (u_x)\n",
    "    \n",
    "    if axis != None:\n",
    "        x = concatenate([x, d_x], axis=axis)\n",
    "    else:\n",
    "        x = concatenate([x, d_x])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본(data), 예측(pred), 라벨(label) 데이터를 화면에 표시하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showCrack(data, pred, label):\n",
    "    \n",
    "    # pyplot의 현재 전체 이미지 크기를 백업 후 설정함\n",
    "    tmp_size = plt.rcParams[\"figure.figsize\"]\n",
    "    plt.rcParams[\"figure.figsize\"] = (15,7)  # 너비, 높이 (in)\n",
    "    \n",
    "    # 원본 데이터 출력\n",
    "    plt.subplot(1,3,1)  # 한 번에 여러 그래프 출력\n",
    "    plt.imshow(data.reshape([512,512]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 예측 데이터 출력\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(pred.reshape([512,512]), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 라벨 데이터 출력\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(label.reshape([512,512]), cmap='gray')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # 백업된 pyplot 이미지 크기를 복원함\n",
    "    plt.rcParams[\"figure.figsize\"] = tmp_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성\n",
    "<변수 명명 규칙><br>\n",
    "→ [과정코드][연산종류코드]_[층수]_[순번]<br>\n",
    "<br>\n",
    "과정코드 : d(down), b(bottle-neck), u(up)<br>\n",
    "연산종류코드 : c(conv), p(pooling), u(upconv), x(copy and crop)<br>\n",
    "층수는 U-Net의 가장 상위층을 1층으로 하여, 하위로 내려갈수록 높아짐<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uNet():\n",
    "\n",
    "    # 균열 이미지 입력 Tensor\n",
    "    inputs = Input((512,512,1))\n",
    "    x = Lambda(lambda x: x) (inputs)\n",
    "\n",
    "    base_filter_cnt = 16\n",
    "\n",
    "    # 압축과정(down) : U의 내려가는 부분\n",
    "    dc_1_1 = conv(x, base_filter_cnt)\n",
    "    dc_1_2 = conv(dc_1_1, base_filter_cnt)\n",
    "    dp_1 = maxpooling(dc_1_2)\n",
    "    print('dp_1 : {}'.format(dp_1))\n",
    "\n",
    "    dc_2_1 = conv(dp_1, base_filter_cnt*2)\n",
    "    dc_2_2 = conv(dc_2_1, base_filter_cnt*2)\n",
    "    dp_2 = maxpooling(dc_2_2)\n",
    "    print('dp_2 : {}'.format(dp_2))\n",
    "\n",
    "    dc_3_1 = conv(dp_2, base_filter_cnt*4)\n",
    "    dc_3_2 = conv(dc_3_1, base_filter_cnt*4)\n",
    "    dp_3 = maxpooling(dc_3_2)\n",
    "    print('dp_3 : {}'.format(dp_3))\n",
    "\n",
    "    # 병목(bottle-neck) : 특징 압축, U의 바닥 부분\n",
    "    bc_4_1 = conv(dp_3, base_filter_cnt*8)\n",
    "    bc_4_2 = conv(bc_4_1, base_filter_cnt*8)\n",
    "    print('\\nbc_4_2 : {}'.format(bc_4_2))\n",
    "\n",
    "    # 확장과정(up) : U의 올라가는 부분\n",
    "    uu_3 = upConv(dc_3_2, bc_4_2, base_filter_cnt*4)\n",
    "    uc_3_1 = conv(uu_3, base_filter_cnt*4)\n",
    "    uc_3_2 = conv(uc_3_1, base_filter_cnt*4)\n",
    "    print('\\nuc_3_2 : {}'.format(uc_3_2))\n",
    "\n",
    "    uu_2 = upConv(dc_2_2, uc_3_2, base_filter_cnt*2)\n",
    "    uc_2_1 = conv(uu_2, base_filter_cnt*2)\n",
    "    uc_2_2 = conv(uc_2_1, base_filter_cnt*2)\n",
    "    print('uc_2_2 : {}'.format(uc_2_2))\n",
    "\n",
    "    uu_1 = upConv(dc_1_1, uc_2_2, base_filter_cnt)\n",
    "    uc_1_1 = conv(uu_1, base_filter_cnt)\n",
    "    uc_1_2 = conv(uc_1_1, base_filter_cnt)\n",
    "    print('uc_1_2 : {}'.format(uc_1_2))\n",
    "\n",
    "    # 최종 출력\n",
    "    pred = conv(uc_1_2, 1, kernel_size=1, activation='sigmoid')\n",
    "    print('\\npred : {}'.format(pred))\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[pred])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(label, pred):\n",
    "\n",
    "    diff = abs(label-pred)  # abs : 절대값 return \n",
    "    weight = 0.97\n",
    "\n",
    "    # Step 함수를 이용한 가중치 설정\n",
    "    loss = backend.mean((backend.sign(activations.relu(diff)) * weight + 1) * backend.square(diff))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩\n",
    "<데이터 구조><br>\n",
    "train_list : 정상 이미지 + 균열 (이미지 개수,512, 512, 1)<br>\n",
    "label_list : 균열 라벨 이미지 (이미지 개수, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train data:  /src/data/crack/Cracks/resize/imgs_crack_train.npy\n",
      "load train label data:  /src/data/crack/Cracks/resize/labels_crack_train.npy\n",
      "(2924, 512, 512, 1)\n",
      "(2924, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"load train data: \", train_list_file)\n",
    "train_list = np.load(train_list_file, allow_pickle=True)\n",
    "print(\"load complete\")\n",
    "\n",
    "print(\"load train label data: \", label_list_file)\n",
    "label_list = np.load(label_list_file, allow_pickle=True)\n",
    "print(\"load complete\")\n",
    "\n",
    "s = np.arange(label_list.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "train_list = train_list[s]\n",
    "label_list = label_list[s]\n",
    "\n",
    "train_list = train_list.astype(np.float32)\n",
    "label_list = label_list.astype(np.float32)\n",
    "\n",
    "print(train_list.shape)\n",
    "print(label_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 로딩\n",
    "모델 로드 및 Multi-GPU 사용 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dp_1 : Tensor(\"max_pooling2d_19/MaxPool:0\", shape=(None, 256, 256, 16), dtype=float32)\n",
      "dp_2 : Tensor(\"max_pooling2d_20/MaxPool:0\", shape=(None, 128, 128, 32), dtype=float32)\n",
      "dp_3 : Tensor(\"max_pooling2d_21/MaxPool:0\", shape=(None, 64, 64, 64), dtype=float32)\n",
      "\n",
      "bc_4_2 : Tensor(\"conv2d_89/Relu:0\", shape=(None, 64, 64, 128), dtype=float32)\n",
      "\n",
      "uc_3_2 : Tensor(\"conv2d_91/Relu:0\", shape=(None, 128, 128, 64), dtype=float32)\n",
      "uc_2_2 : Tensor(\"conv2d_93/Relu:0\", shape=(None, 256, 256, 32), dtype=float32)\n",
      "uc_1_2 : Tensor(\"conv2d_95/Relu:0\", shape=(None, 512, 512, 16), dtype=float32)\n",
      "\n",
      "pred : Tensor(\"conv2d_96/Relu:0\", shape=(None, 512, 512, 1), dtype=float32)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 512, 512, 1)  0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 512, 512, 16) 800         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 512, 512, 16) 12560       conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 256, 256, 16) 0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 256, 256, 32) 25120       max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 256, 256, 32) 50208       conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 128, 128, 32) 0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 128, 128, 64) 100416      max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 128, 128, 64) 200768      conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 64, 64, 64)   0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 64, 64, 128)  401536      max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 64, 64, 128)  802944      conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 128, 128, 64) 401472      conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 128, 128, 128 0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 128, 128, 64) 401472      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 128, 128, 64) 200768      conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 256, 256, 32) 100384      conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 256, 256, 64) 0           conv2d_transpose_14[0][0]        \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 256, 256, 32) 100384      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 256, 256, 32) 50208       conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 512, 512, 16) 25104       conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 512, 512, 32) 0           conv2d_transpose_15[0][0]        \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 512, 512, 16) 25104       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 512, 512, 16) 12560       conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 512, 512, 1)  17          conv2d_95[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,911,825\n",
      "Trainable params: 2,911,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model = uNet()\n",
    "\n",
    "# 멀티 GPU 사용\n",
    "# model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss, optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=learning_rate), loss=customLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2924/2924 [==============================] - 112s 38ms/step - loss: 0.0409\n",
      "Epoch 2/5\n",
      "2924/2924 [==============================] - 105s 36ms/step - loss: 0.0348\n",
      "Epoch 3/5\n",
      "2924/2924 [==============================] - 109s 37ms/step - loss: 0.0325\n",
      "Epoch 4/5\n",
      "2924/2924 [==============================] - 107s 37ms/step - loss: 0.0311\n",
      "Epoch 5/5\n",
      "2924/2924 [==============================] - 106s 36ms/step - loss: 0.0300\n"
     ]
    }
   ],
   "source": [
    "# 과적합 방지 설정값 및 checkpoint 생성 설정값\n",
    "earlystopper = EarlyStopping(patience=5, verbose=2)\n",
    "checkpointer = ModelCheckpoint(model_dir + '.ckpt', verbose=2, save_best_only=True)\n",
    "\n",
    "# 학습\n",
    "results = model.fit(train_list, label_list, \n",
    "                    epochs = epoch_count,\n",
    "                    batch_size=training_count,\n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model: /src/hyebin/model/TEST/KERAS-TEST-1\n",
      "\n",
      "complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"save model: %s\"%model_dir)\n",
    "\n",
    "model.save(model_dir)\n",
    "\n",
    "print(\"\\ncomplete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
