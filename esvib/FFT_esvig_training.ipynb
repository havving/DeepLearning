{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data :  /src/data/DataSet/FFTData.npy\n",
      "load complete\n",
      "WARNING:tensorflow:From <ipython-input-1-17136314518d>:72: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-17136314518d>:86: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-17136314518d>:115: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-17136314518d>:116: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "index= 0   loss= 0.8019243\n",
      "index= 100   loss= 0.4538477\n",
      "index= 200   loss= 0.12017423\n",
      "index= 300   loss= 0.037116613\n",
      "index= 400   loss= 0.015008687\n",
      "index= 500   loss= 0.009524986\n",
      "index= 600   loss= 0.005668774\n",
      "index= 700   loss= 0.008854443\n",
      "index= 800   loss= 0.0005409646\n",
      "index= 900   loss= 0.0004157069\n",
      "index= 1000   loss= 0.00030895442\n",
      "index= 1100   loss= 0.00052108953\n",
      "index= 1108   loss= 8.528254e-05\n",
      "running time :  93.74000525474548\n",
      "save model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /src/hyebin/model/FFT-01/saved_model.pb\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# --- 설정 변수 정의 ---\n",
    "# 작업 디렉토리 정의\n",
    "# 학습 데이터 파일명\n",
    "datafile = \"/src/data/DataSet/FFTData.npy\"\n",
    "# 진동 분석 모델 디렉토리명\n",
    "modeldir = \"/src/hyebin/model/FFT-01\"\n",
    "# tensorboard용 log 디렉토리명\n",
    "tblogdir = \"/src/hyebin/logs\"\n",
    "\n",
    "# 학습 데이터 설정\n",
    "# 학습 데이터 중 최초 데이터 위치\n",
    "base_index = 2000\n",
    "# 학습할 데이터의 개수\n",
    "training_count = 1000\n",
    "\n",
    "# 전결합층 설정\n",
    "# 전결합층 첫번째 레이어 unit 개수\n",
    "layer1_unit_count = 1024\n",
    "# 전결합층 두번째 레이어 unit 개수\n",
    "layer2_unit_count = 1024\n",
    "# 전결합층 두번째 레이어 unit 개수\n",
    "layer3_unit_count = 1024\n",
    "# 전결합층 dropout 비율\n",
    "dropout_rate = 0.4\n",
    "\n",
    "# 최적화 함수 설정\n",
    "# 최적화 함수 학습률\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# 학습 수행 설정\n",
    "# 최대 학습 수행 회수\n",
    "epoch_count = 5000\n",
    "# 학습 중단 시킬 최소 loss값\n",
    "loss_limit = 0.0001\n",
    "\n",
    "\n",
    "# --- 학습 데이터 로딩  ---\n",
    "# 데이터 구조\n",
    "# data[0] : 학습용 데이터(이미지 개수, 36, 48, 3)\n",
    "# data[1] : 테스트용 데이터(이미지 개수, 36, 48, 3)\n",
    "# data[2] : 학습용 데이터의 라벨(이미지 개수, 5)\n",
    "# data[3] : 테스트용 데이터의 라벨 (이미지 개수, 5)\n",
    "print(\"load data : \", datafile)\n",
    "data = np.load(datafile, allow_pickle=True)\n",
    "print(\"load complete\")\n",
    "\n",
    "# 학습용 데이터와 라벨을 사용함\n",
    "train_x = data[0][base_index:base_index + training_count]\n",
    "train_y = data[2][base_index:base_index + training_count]\n",
    "\n",
    "# --- VGG Net 신경망 구성 ---\n",
    "# 입력층 : 36*48 의 Spectrogram 전처리 데이터\n",
    "# 특징 추출층 : 2개 합성곱 필터, 1개의 필터를 2회 수행 \n",
    "# 전 결합층 : 3개의 은닉층(층당 유닛 1024개) -> 단층에서 발생하는 xor 문제 회피, 1개의 출력층(유닛 5개)\n",
    "use_dropout = tf.placeholder(tf.bool, name=\"use_dropout\")\n",
    "\n",
    "# --- 입력층 ---\n",
    "x = tf.placeholder(tf.float32, [None, 36, 48, 3], name=\"in\")\n",
    "\n",
    "# --- 특징 추출층 ---\n",
    "conv11 = tf.layers.conv2d(\n",
    "    inputs=x,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "conv12 = tf.layers.conv2d(\n",
    "    inputs=conv11,\n",
    "    filters=32,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# 풀링으로 사이즈가 줄어듦\n",
    "# FFT : 36 * 48 → 18 * 24\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    inputs=conv12,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2)\n",
    "\n",
    "conv21 = tf.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "conv22 = tf.layers.conv2d(\n",
    "    inputs=conv21,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "# 풀링으로 사이즈가 줄어듦\n",
    "# FFT : 18 * 24 → 9 * 12\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "    inputs=conv22,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2)\n",
    "\n",
    "# --- 전 결합층 ---\n",
    "# 데이터 행렬 평탄화(flatten)\n",
    "# FFT : 9 * 12(이미지사이즈) * 64(합성곱 필터 수)\n",
    "input_cnt = 9 * 12 * 64\n",
    "pool_flat = tf.reshape(pool2, [-1, input_cnt])\n",
    "\n",
    "dense1 = tf.layers.dense(inputs=pool_flat, units=layer1_unit_count, activation=tf.nn.relu)\n",
    "dropout1 = tf.layers.dropout(inputs=dense1, rate=dropout_rate, training=use_dropout)\n",
    "\n",
    "dense2 = tf.layers.dense(inputs=dropout1, units=layer2_unit_count, activation=tf.nn.relu)\n",
    "dropout2 = tf.layers.dropout(inputs=dense2, rate=dropout_rate, training=use_dropout)\n",
    "\n",
    "dense3 = tf.layers.dense(inputs=dropout2, units=layer3_unit_count, activation=tf.nn.relu)\n",
    "dropout3 = tf.layers.dropout(inputs=dense3, rate=dropout_rate, training=use_dropout)\n",
    "\n",
    "netout = tf.layers.dense(inputs=dropout3, units=5)\n",
    "softout = tf.nn.softmax(netout, name=\"out\")\n",
    "\n",
    "# --- loss 함수 정의 ---\n",
    "# 평균 제곱 오차 함수 사용\n",
    "y = tf.placeholder(tf.float32, [None, 5])\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(softout - y), 1))\n",
    "loss_summ = tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# --- loss 함수의 최적화 함수 정의 ---\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# --- 학습 수행 ---\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard용 로깅 정의    \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(tblogdir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    # 신경망 가중치(weight) 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 전체 데이터에 대해 5000번 수행\n",
    "    # loss가 0.001 이하일 때, 학습 중단\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch_count):\n",
    "        _train, _loss_summ, _loss = sess.run([train, loss_summ, loss], feed_dict={x:train_x, y:train_y, use_dropout:True})\n",
    "        writer.add_summary(summary = _loss_summ, global_step = epoch)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"index=\", epoch, \"  loss=\", _loss)\n",
    "            \n",
    "        if _loss < loss_limit:\n",
    "            print(\"index=\", epoch, \"  loss=\", _loss)\n",
    "            break\n",
    "            \n",
    "    end_time = time.time()\n",
    "    print(\"running time : \", end_time - start_time)\n",
    "    \n",
    "    # --- 학습 모델 저장 ----\n",
    "    print(\"save model\")\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(modeldir)\n",
    "    signature = tf.saved_model.predict_signature_def(inputs={\"in\":x}, outputs={\"out\":softout})\n",
    "    builder.add_meta_graph_and_variables(sess, tags=[\"ver1\"], signature_def_map={\"escalator-vibration-analysis-v1\":signature})\n",
    "    builder.save()\n",
    "    print(\"complete\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
